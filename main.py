# -*- coding: utf-8 -*-

import requests
import json
import time
from urllib.parse import urlparse, parse_qs
import os
import subprocess
import logging
import signal
import threading

from ModelType import ModelType
from BaseModelType import BaseModelType
from util.file_util import file_util
from util.SQLiteDB import SQLiteDB
from logging.handlers import TimedRotatingFileHandler
from util.DownloadUtil import DownloadUtil
from util.logger_utils import setup_global_logger

db = SQLiteDB()
db.init_db()
keyboard_interrupted = False
# è·å– TOKEN
TOKEN = None
CID = None
autoDownload = None
download_three_number = 1
# æ¨¡å‹å­˜æ”¾çˆ¶çº§è·¯å¾„ï¼Œè¿™å¯ä»¥ä¿®æ”¹ï¼Œä¹Ÿå¯ä»¥ä¿®æ”¹ModelTypeä¸­æ–‡ä»¶è·¯å¾„
model_file_parent_dir = None
baseUrl = 'https://api2.liblib.art/api/www'
# æœç´¢æ¨¡å‹åˆ—è¡¨
searchModels = "/model/search"
# è·å–æ¨¡å‹è¯¦æƒ…
getModelInfo = "/model/getByUuid/"
# æ¨èæ¨¡å‹
recommendModels = "/model-version/modelVersion/listByIds"
# æ ¡éªŒä¸‹è½½åœ°å€
checkDownloadUrl = "/community/downloadCheck"
# è·å–ä¸‹è½½åœ°å€
getDownloadUrl = "/model/download/"

logger = logging.getLogger(__name__)


# æœç´¢æ¨¡å‹åˆ—è¡¨
def search_model(keyword, types=[], models=[], vipType=[]):
    '''

    :param keyword: æœç´¢å†…å®¹
    :param types:  æœç´¢çš„åŸºæ¨¡ç±»å‹
        1 åŸºç¡€ç®—æ³• v1.5
        2 åŸºç¡€ç®—æ³• v2.1
        3 åŸºç¡€ç®—æ³• XL
        7 åŸºç¡€ç®—æ³• v3
        9 PixArt Î£
        10 Pony
        12 æ··å…ƒDiT v1.1
        13 PixArt Î±
        19 åŸºç¡€ç®—æ³• F.1
        20 åŸºç¡€ç®—æ³• v3.5M
        21 åŸºç¡€ç®—æ³• v3.5L
    :param models: æ¨¡å‹ç±»å‹
        1 Checkpoint
        2 Textual Inversion
        3 Hypernetwork
        4 Aesthetic Gradient
        5 LoRA
        6 LyCORIS
        7 Controlnet
        8 Poses
        9 Wildcards
        10 Other
    :param vipType: ä¼šå‘˜ä¸“å±
        0 å…è´¹æ¨¡å‹
        1 ä¼šå‘˜ä¸“å±
        2 ä»…ä¼šå‘˜å¯ä¸‹è½½
    :return:
    '''
    logger.info("å…¨é‡è·å–æ•°æ®ä¸­ï¼Œè¯·ç­‰å¾…...")

    bodys = {
        'keyword': keyword,
        'periodTime': ["all"],
        'page': 1,
        'pageSize': 50,
        'types': types,
        'models': models,
        'vipType': vipType,
    }

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36'
    }

    datas = []

    while True:
        logger.info("æ­£åœ¨è·å–ç¬¬ " + str(bodys["page"]) + " é¡µæ•°æ®...")
        time.sleep(1)
        params = {
            'timestamp': time.time()
        }
        response = requests.post(baseUrl + searchModels, params=params, json=bodys, headers=headers)
        json_data = response.json()
        bodys["page"] = bodys["page"] + 1
        # logger.info(json.dumps(json_data, ensure_ascii=False))
        if not json_data["data"]["hasMore"]:
            break
        else:
            # logger.info(json.dumps(json_data.json(), ensure_ascii=False))
            # å°†æ•°ç»„å­˜æ”¾åˆ° æ•°ç»„ä¸­
            for item in json_data["data"]["data"]:
                datas.append(item['uuid'])
    logger.info("è·å–æ•°æ®å®Œæˆï¼Œå…±æœ‰ " + str(len(datas)) + " æ¡æ•°æ®")
    return datas


# è·å–æ¨¡å‹è¯¦æƒ…
def get_model_info(model_id):
    if model_id is None:
        return None
    '''
    :param model_id:
    :return:
    modelType:
        1 Checkpoint
        2 Textual Inversion
        3 Hypernetwork
        4 Aesthetic Gradient
        5 LoRA
        6 LyCORIS
        7 Controlnet
        8 Poses
        9 Wildcards
        10 Other
    '''
    params = {
        'timestamp': time.time()
    }
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36'
    }
    res = requests.post(baseUrl + getModelInfo + model_id, params=params, headers=headers)
    # logger.info(json.dumps(res.json(), ensure_ascii=False))
    if res.json()["code"] == 0:
        return res.json()["data"]
    else:
        return None


# è·å–æ­é…æ¨¡å‹
def get_recommend_model(versionIds):
    params = {
        'timestamp': time.time()
    }
    bodys = {
        'versionIds': versionIds
    }
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36'
    }
    res = requests.post(baseUrl + recommendModels, json=bodys, params=params, headers=headers)
    # æ‰“å°åŒå¼•å·json
    # logger.info(json.dumps(res.json(), ensure_ascii=False))
    return res.json()


# è·å–ä¸‹è½½åœ°å€
def get_download_url(model_uuid, model_url):
    params = url_params_to_json(model_url)
    params['timestamp'] = time.time()
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36',
        'token': TOKEN
    }
    # logger.info(json.dumps(params, ensure_ascii=False))
    res = requests.get(baseUrl + getDownloadUrl + model_uuid, params=params, headers=headers)
    # logger.info(json.dumps(res.json(), ensure_ascii=False))
    if res.json()["code"] == 0:
        return res.json()["data"]
    else:
        if res.json()["msg"] == 'ä¸‹è½½è¶…è¿‡é™åˆ¶':
            logger.warning("ä¸‹è½½è¶…è¿‡é™åˆ¶ï¼Œè¯·æ›´æ¢è´¦å·TOKENåé‡æ–°ä¸‹è½½")
            exit()
        return res.json()["msg"]
    return None


# æ ¡éªŒä¸‹è½½
def get_check_download(model_id, model_name, model_version_id, model_url, model_uuid):
    params = {
        'timestamp': time.time()
    }
    bodys = {
        "cid": CID,
        'modelId': model_id,
        'modelName': model_name,
        'modelVersionId': model_version_id,
        'url': model_url,
        'uuid': model_uuid,
    }
    # logger.info(json.dumps(bodys, ensure_ascii=False))

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36'
    }
    res = requests.post(baseUrl + checkDownloadUrl, json=bodys, params=params, headers=headers)
    # logger.info(json.dumps(res.json(), ensure_ascii=False))
    return res.json()["data"]


def url_params_to_json(url):
    # è§£æ URL
    parsed_url = urlparse(url)

    # æå–æŸ¥è¯¢å‚æ•°
    params_dict = parse_qs(parsed_url.query)

    # å°†å‚æ•°å­—å…¸è½¬æ¢ä¸º JSON å¯¹è±¡
    params_json = {k: v[0] for k, v in params_dict.items()}
    return params_json


# è·å–æ–‡ä»¶åç¼€
def get_url_suffix(url):
    parsed_url = urlparse(url)
    path = parsed_url.path
    # è·å–æ–‡ä»¶æ‰©å±•åï¼ˆåŒ…å«ç‚¹å·ï¼‰
    ext = os.path.splitext(path)[1]
    return ext


# é€šè¿‡é“¾æ¥è·å–æ¨¡å‹ID
def get_model_id_by_url(url):
    parsed_url = urlparse(url)
    path = parsed_url.path
    if path.rfind('/') != -1:
        return path[path.rfind('/') + 1:]
    if len(path) == 32:
        return path
    logger.warning("æ— æ³•è·å–æ¨¡å‹ç¼–å·")
    return None


# è·å–é…å¥—æ¨¡å‹
def get_compatible_model(versionIds=[]):
    if len(versionIds) == 0:
        return None

    params = {
        'timestamp': time.time()
    }

    bodys = {
        "versionIds": versionIds
    }
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36'
    }
    res = requests.post(baseUrl + recommendModels, json=bodys, params=params, headers=headers)
    # logger.info(json.dumps(res.json(), ensure_ascii=False))
    return res.json()["data"]


# è·å–æ¨¡å‹ç›´è¿åœ°å€
def get_direct_link(model_uuid):
    if model_uuid is None:
        return None
    if db.is_model_downloaded(model_uuid):
        logger.warning("æ¨¡å‹å·²ä¸‹è½½")
        return None
    model_info = get_model_info(model_uuid)
    if model_info:
        model_id = model_info["id"]
        # model_uuid = model_info["uuid"]
        model_name = model_info["name"]
        # TODO åç»­éœ€è¦å¢åŠ æ˜ç¡®çš„è¿‡æ»¤ï¼šå› ä¸ºæœªç™»å½•å¯¼è‡´ä¸‹è½½å¤±è´¥çš„ä¸åº”è¯¥å­˜æ”¾
        db.insert_model_info(model_uuid, model_name=model_name, model_info=json.dumps(model_info, ensure_ascii=False))
        model_type = model_info["modelType"]
        # è¿™é‡Œé»˜è®¤è·å–æœ€æ–°ç‰ˆæœ¬
        model_version_name = model_info["versions"][0]["name"]
        if model_info["versions"][0]["attachment"] is None:
            return None
        model_version_url = model_info["versions"][0]["attachment"]["modelSource"]
        model_version_desc = model_info["versions"][0]["versionDesc"]
        model_version_id = model_info["versions"][0]["id"]
        model_version_uuid = model_info["versions"][0]["uuid"]
        if model_info["versions"][0]["versionIntro"]:
            model_version_versionIntro = json.loads(model_info["versions"][0]["versionIntro"])
            if "ckpt" in model_version_versionIntro:
                base_model = model_version_versionIntro['ckpt']
                compatible_models = get_compatible_model(base_model)
                if compatible_models:
                    # logger.info("é…å¥—æ¨¡å‹ï¼š")
                    for compatible_model in compatible_models:
                        # logger.info(
                        #     f'æ¨¡å‹id ï¼š {compatible_model["id"]}\r\n'
                        #     f'æ¨¡å‹UUID ï¼š {compatible_model["modelUuid"]}\r\n'
                        #     f'æ¨¡å‹åç§° ï¼š {compatible_model["modelName"]}\r\n'
                        #     f'æ¨¡å‹ç±»å‹ ï¼š {BaseModelType(compatible_model["baseType"]).desc()}\r\n'
                        #     f'æ¨¡å‹ç‰ˆæœ¬åç§° ï¼š{compatible_model["modelVersionName"]}\r\n'
                        # )
                        get_direct_link(compatible_model['modelUuid'])

        check_download = get_check_download(model_id, model_name, model_version_uuid, model_version_url, model_uuid)
        if check_download:
            download_url = get_download_url(model_uuid, model_version_url)
            # logger.info(
            #     f'æ¨¡å‹åç§° ï¼š {model_name}\r\n'
            #     f'æ¨¡å‹ç±»å‹ ï¼š {ModelType(model_type).desc()}\r\n'
            #     f'æ¨¡å‹ä¸‹è½½åœ°å€ ï¼š{download_url}\r\n'
            #     f'æ¨¡å‹ä»‹ç» ï¼š{model_version_desc}\r\n'
            #     f'æ¨èå‚æ•° ï¼š{model_version_versionIntro}\r\n'
            # )
            if download_url:
                url_suffix = get_url_suffix(download_url)
                model_path = f"{model_file_parent_dir}{ModelType(model_type).file_path()}/{model_name}({model_version_name}){url_suffix}"
                logger.info(
                    f'# {model_name}({model_version_name})  æ¨¡å‹é“¾æ¥ï¼ˆhttps://www.liblib.art/modelinfo/{model_uuid}ï¼‰')
                logger.info(f'!wget -c "{download_url}" -O "{model_path}"')
                if autoDownload:
                    # wget_download_model(download_url, model_path)
                    download_model_file(download_url, model_path)
                    save_model_info(model_info)
                    download_model_cover(model_info)  # æ–°å¢è°ƒç”¨
                # logger.info("================================================================")
            else:
                logger.warning(f"è·å–æ¨¡å‹({model_name})ä¸‹è½½åœ°å€å¤±è´¥ï¼Œè¯·æ£€æŸ¥å½“å‰è´¦å·æ˜¯å¦æœ‰ä¸‹è½½æƒé™")
        else:
            logger.warning("ä¸‹è½½æ ¡éªŒå¤±è´¥")
    else:
        logger.warning("æ¨¡å‹ä¸å­˜åœ¨")
    time.sleep(1)


# ä½¿ç”¨wgetä¸‹è½½æ–‡ä»¶
def wget_download_model(download_url, model_path):
    logger.info(f"æ­£åœ¨ä¸‹è½½æ–‡ä»¶ï¼š{download_url} è‡³ {model_path}")

    os.makedirs(os.path.dirname(model_path), exist_ok=True)

    # åˆ¤æ–­æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    if os.path.exists(model_path):
        logger.warning(f"âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {model_path}")
        return

    download_cmd = [
        'wget', '-c',
        download_url,
        '-O',
        f"{model_path}"
    ]

    logger.info("æ­£åœ¨æ‰§è¡Œä¸‹è½½å‘½ä»¤ï¼š")
    logger.info(' '.join(download_cmd))

    try:
        result = subprocess.run(download_cmd, check=True)
        logger.info("âœ… ä¸‹è½½å®Œæˆ")
    except subprocess.CalledProcessError as e:
        logger.warning(f"âŒ ä¸‹è½½å¤±è´¥: {e}")


# ä¸‹è½½æ–‡ä»¶
def download_model_file(download_url, model_path):
    logger.info(f"æ­£åœ¨ä¸‹è½½æ–‡ä»¶ï¼š{download_url} è‡³ {model_path}")

    os.makedirs(os.path.dirname(model_path), exist_ok=True)

    # åˆ¤æ–­æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    if os.path.exists(model_path):
        logger.warning(f"âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {model_path}")
        return
    
    downloader = DownloadUtil(max_retries=3, retry_wait=5)
    # downloader.download_file(download_url, model_path)
    downloader.download_file_multi_threaded(download_url, model_path, num_threads=download_three_number)


# ä¿å­˜æ¨¡å‹åŸå§‹æ•°æ®
def save_model_info(model_info):
    if model_info:
        model_name = model_info["name"]
        model_type = model_info["modelType"]
        # è¿™é‡Œé»˜è®¤è·å–æœ€æ–°ç‰ˆæœ¬
        model_version_name = model_info["versions"][0]["name"]
        info_file_json = f"{model_file_parent_dir}{ModelType(model_type).file_path()}/{model_name}({model_version_name}).json"
        # åˆ¤æ–­æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if os.path.exists(info_file_json):
            logger.warning(f"âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {info_file_json}")
            return
        # å°†æ–‡æœ¬å†™å…¥æ–‡ä»¶
        with open(info_file_json, 'w', encoding='utf-8') as f:
            json.dump(model_info, f, ensure_ascii=False, indent=4)
            logger.info(f"å·²ä¿å­˜æ¨¡å‹ä¿¡æ¯è‡³ {info_file_json}")


# ä¸‹è½½å°é¢å›¾ç‰‡
def download_model_cover(model_info):
    if model_info:
        model_name = model_info["name"]
        model_type = model_info["modelType"]
        # è¿™é‡Œé»˜è®¤è·å–æœ€æ–°ç‰ˆæœ¬
        model_version_name = model_info["versions"][0]["name"]
        cover_url = model_info["versions"][0]["imageGroup"]["coverUrl"]
        img_suffix = get_url_suffix(cover_url)
        file_path = f"{model_file_parent_dir}{ModelType(model_type).file_path()}/{model_name}({model_version_name}){img_suffix}"
        # åˆ¤æ–­æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if os.path.exists(file_path):
            logger.warning(f"âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {file_path}")
            return
        # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        # ä¸‹è½½å›¾ç‰‡
        try:
            response = requests.get(cover_url, stream=True)
            response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚çŠ¶æ€
            with open(file_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=1024):
                    if chunk:
                        f.write(chunk)
            logger.info(f"âœ… å°é¢å›¾ç‰‡å·²æˆåŠŸä¸‹è½½è‡³: {file_path}")
        except requests.exceptions.RequestException as e:
            logger.warning(f"âŒ ä¸‹è½½å°é¢å›¾ç‰‡å¤±è´¥: {e}")


# åˆå§‹åŒ–å‚æ•°
def init():
    global TOKEN, CID, autoDownload, model_file_parent_dir
    setup_global_logger(log_level=logging.INFO)  # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    # setup_logging()  # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    logger.info("å¼€å§‹åˆå§‹åŒ–ç¨‹åº...")
    # è·å– TOKEN
    config = file_util.read_yml()

    user_conf = config.get('user')
    TOKEN = user_conf['token']
    CID = user_conf['cid']

    down_conf = config.get('download')
    model_file_parent_dir = down_conf['model_parent_path']
    autoDownload = down_conf['auto_download']
    download_three_number = down_conf['three_number']

    if TOKEN:
        logger.info(f"æˆåŠŸè¯»å– TOKEN : {TOKEN}")
    else:
        logger.warning("æœªæ‰¾åˆ° TOKENï¼Œè¯·æ£€æŸ¥ conf.yml æ–‡ä»¶")
        exit()

    if CID:
        logger.info(f"æˆåŠŸè¯»å– CID : {CID}")
    else:
        logger.warning("æœªæ‰¾åˆ° CIDï¼Œè¯·æ£€æŸ¥ conf.yml æ–‡ä»¶")
        exit()


# èœå•
def menu():
    print("===============================")
    print("0. è¿”å›èœå•")
    print("1. æœç´¢è‡ªåŠ¨æ¨¡å‹")
    print("2. é€šè¿‡é“¾æ¥ä¸‹è½½æ¨¡å‹")
    print("q. é€€å‡º")
    print("===============================")
    choice = input("è¯·é€‰æ‹©ï¼š")
    if choice == "0":
        menu()
    elif choice == "1":
        print("è¯·è¾“å…¥å…³é”®å­—ï¼š")
        search_model_download_menu()
    elif choice == "2":
        download_model_menu()


def download_model_menu():
    # æ¥æ”¶è¾“å…¥
    print("è¯·è¾“å…¥æ¨¡å‹é“¾æ¥ï¼š")
    print(
        "æ ·ä¾‹ï¼šhttps://www.liblib.art/modelinfo/c4dbdde32eef41618b514b126aedb853?from=search&versionUuid=9248fef8f5074c3eb5f43d5f28838bef")
    while True:
        url = input("ç²˜è´´åœ¨è¿™é‡Œï¼ˆè¾“å…¥ q é€€å‡ºç¨‹åºï¼Œè¾“å…¥ 0 è¿”å›èœå•ï¼‰ï¼š")
        if url == "0":
            menu()
            break
        if url == "q":
            exit()
            break
        if url == "":
            print("è¯·è¾“å…¥æ¨¡å‹é“¾æ¥ï¼š")
            continue
        model_uuid = get_model_id_by_url(url)
        if model_uuid is None:
            print("æ— æ³•è·å–æ¨¡å‹ç¼–å·")
            continue
        get_direct_link(model_uuid)


def search_model_download_menu():
    # æ¥æ”¶è¾“å…¥
    print("è¯·è¾“å…¥æœç´¢å…³é”®å­—ï¼š")
    print("æ ·ä¾‹ï¼šæƒ…è¶£")
    while True:
        order = input("å…³é”®å­—ï¼ˆè¾“å…¥ q é€€å‡ºç¨‹åºï¼Œè¾“å…¥ 0 è¿”å›èœå•ï¼‰ï¼š")
        if order == "0":
            menu()
            break
        if order == "q":
            exit()
            break
        if order == "":
            print("è¯·è¾“å…¥æœç´¢å…³é”®å­—ï¼š")
            continue
        uuids = search_model(order)
        for uuid in uuids:
            get_direct_link(uuid)

def keyboard_listener():
    global keyboard_interrupted
    input()  # ç­‰å¾…ä»»æ„è¾“å…¥
    keyboard_interrupted = True


def signal_handler(sig, frame):
    logger.info("\n\næ£€æµ‹åˆ° Ctrl+C æˆ–ç³»ç»Ÿç»ˆæ­¢ä¿¡å·ï¼Œæ­£åœ¨å®‰å…¨é€€å‡º...")
    for handler in logging.root.handlers:
        handler.flush()
    db.close()
    print("\nğŸ‘‹ ç¨‹åºå·²ç»ˆæ­¢ã€‚æ„Ÿè°¢ä½¿ç”¨ï¼")
    exit(0)


if __name__ == '__main__':
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    try:
        init()

        # å¯åŠ¨åå°é”®ç›˜ç›‘å¬çº¿ç¨‹
        # listener_thread = threading.Thread(target=keyboard_listener, daemon=True)
        # listener_thread.start()

        menu()
    except Exception as e:
        logger.error(f"å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
        print("âŒ ç¨‹åºå› å¼‚å¸¸ç»ˆæ­¢ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—è·å–æ›´å¤šä¿¡æ¯ã€‚")
        exit(1)
